defaults:
  - _self_
  - override hydra/launcher: submitit_slurm
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe

compute:
  ngpus: 1
  nodes: 1

logging:
  log_freq: 100
  log_lr_every: ${logging.log_freq}
  log_file_name: stdout.log
  enable_wandb: True
  entity: mattias421
  project: flow_matching
  group: null

data:
  train: librispeech
  valid: librispeech
  cache_dir: /path/to/cache/dir
  num_workers: 8
  debug: false
  max_decode_ratio: 1

training:
  batch_size: 128
  snapshot: 500
  eval_freq: 500
  perplexity_freq: 5000000
  cer_freq: 1000
  seed: 42
  unsupervised: false
  partial_loss_weight: 1

eval:
  batch_size: 128
  sample_batch_size: 16
  perplexity: True
  perplexity_batch_size: 128
  n_gen_iter: 8
  kenlm_path: /path/to/kenlm

optim:
  weight_decay: 0.03
  optimizer: AdamW
  lr: 1e-3
  beta1: 0.9
  beta2: 0.95
  eps: 1e-8
  warmup: 200
  grad_clip: 1.
  eta_min_ratio: 0.1
  fused: false
  n_iters: 60000
  log_lr_every: ${logging.log_lr_every}

flow:
  source_distribution: asr  # [asr]
  loss_function: cross_entropy  # [cross_entropy, generalized_kl]
  exponent: 1.
  scheduler_type: polynomial
  sampling_steps: 64
  partial_noise_prob: 0.01

model:
  hidden_size: 768
  cond_dim: 128
  length: 1024
  n_blocks: 12
  n_heads: 12
  dropout: 0
  compile: true

hydra_dir: /path/to/hydra/dir

hydra:
  run:
    dir: ${hydra_dir}/${now:%Y.%m.%d}/${now:%H%M%S}
  sweep:
    dir: ${hydra_dir}/${now:%Y.%m.%d}/${now:%H%M%S}
    subdir: ${hydra.job.num}
  launcher:
    max_num_timeout: 100000
    timeout_min: 4320
    partition: gpu,gpu-h100,gpu-h100-nvl
    qos: gpu:1
    gpus_per_node: ${compute.ngpus}
    cpus_per_task: 8
    mem_gb: null
    mem_per_cpu: null
    mem_per_gpu: null
    srun_args:
        - --export=ALL
    setup:
        - export WANDB_TAGS="unsoup_bowl"
        - ml binutils GCCcore GCC libsndfile cuDNN bzip2
        - source .venv/bin/activate
  sweeper:
    sampler:
      seed: 123
    direction: minimize
    study_name: unsoup_bowl
    # storage: null
    n_trials: 36
    n_jobs: 12
    # max_failure_rate: 0.5
    params:
        optim.lr: tag(log, interval(0.0004, 0.002))
        optim.warmup: choice(2000,2500,3000,3500,4000)
        optim.weight_decay: tag(log, interval(0.0004, 0.006))
        flow.partial_noise_prob: choice(0,0.01,0.05,0.1)
        model.dropout: range(0.05,0.3,step=0.05)


